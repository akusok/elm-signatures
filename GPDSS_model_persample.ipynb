{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify single image patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not expected to be very precise - more of a model structure search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"export MKL_NUM_THREADS=4\")\n",
    "os.system(\"export NUMEXPR_NUM_THREADS=4\")\n",
    "os.system(\"export OMP_NUM_THREADS=4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyarrow import parquet\n",
    "\n",
    "import skelm\n",
    "\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set(rc={'figure.figsize':(15, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, cross_val_score, GridSearchCV, GroupShuffleSplit, RandomizedSearchCV\n",
    "import scipy\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = '50p'\n",
    "MAX_SAMPLES_PER_FILE = 30\n",
    "# data_path = \"/scratch/project_2001220/leonardo/00_Features/GPDSS10000/folder2/004/overlap\" + overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user(fname):\n",
    "    for root,_,files in os.walk(os.path.dirname(fname) + \"/overlap\" + overlap):\n",
    "        pq_files = [os.path.join(root, f) for f in files if f.endswith(\"_features.parquet.gz\")]\n",
    "    \n",
    "    def _load(path):\n",
    "        X = np.array(parquet.read_table(path, use_threads=False))[6:]\n",
    "        X = X[:, np.random.choice(X.shape[1], MAX_SAMPLES_PER_FILE, replace=False)].T\n",
    "        y = np.ones((MAX_SAMPLES_PER_FILE, 1), np.float32) * int(\"/cf-\" in path)\n",
    "        return X, y\n",
    "  \n",
    "    print(\".\", end=\"\")\n",
    "    data = [_load(a) for a in pq_files]\n",
    "    X = np.vstack([d[0] for d in data]).astype(np.float32)\n",
    "    y = np.vstack([d[1] for d in data])\n",
    "    return np.hstack((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_pickle(\"df_data.pkl.gz\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "with Pool(12) as p:\n",
    "    data = np.vstack(p.map(load_user, df_files.file))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save(\"/scratch/project_2001220/anton/data_all.npy\", data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = np.load(\"/scratch/project_2001220/anton/data_1m.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data_200k.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207360, 1025)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : False\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : False\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810.791130065918"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(np.array(data, dtype=np.float32)) / 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1 µs, total: 11 µs\n",
      "Wall time: 12.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 718 ms, sys: 19.7 ms, total: 737 ms\n",
      "Wall time: 745 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# normalize data in a low-memory way\n",
    "\n",
    "m = x.mean(axis=0)\n",
    "x -= m\n",
    "l = x.shape[0]\n",
    "s = np.array([(np.sum(col**2)/l)**0.5 for col in x.T])\n",
    "x /= s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 602 ms, sys: 262 ms, total: 864 ms\n",
      "Wall time: 869 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-3.06963926e-07, -1.04492095e-08,  4.19440083e-09, ...,\n",
       "        -1.83964954e-09, -3.94052933e-08,  7.86634118e-08], dtype=float32),\n",
       " array([1.        , 1.        , 1.        , ..., 0.9999999 , 0.99999994,\n",
       "        1.        ], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x.mean(0), x.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 ms, sys: 235 ms, total: 936 ms\n",
      "Wall time: 945 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = np.ascontiguousarray(x)\n",
    "y = np.ascontiguousarray(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "sns.histplot(x.ravel())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "plt.hist(x.ravel(), bins='auto')\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blas_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/akusok/miniconda3/envs/signatures/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/akusok/miniconda3/envs/signatures/include']\n",
      "blas_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/akusok/miniconda3/envs/signatures/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/akusok/miniconda3/envs/signatures/include']\n",
      "lapack_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/akusok/miniconda3/envs/signatures/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/akusok/miniconda3/envs/signatures/include']\n",
      "lapack_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/akusok/miniconda3/envs/signatures/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/akusok/miniconda3/envs/signatures/include']\n",
      "Supported SIMD extensions in this NumPy install:\n",
      "    baseline = SSE,SSE2,SSE3\n",
      "    found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2\n",
      "    not found = AVX512F,AVX512CD,AVX512_KNL,AVX512_SKX,AVX512_CLX,AVX512_CNL,AVX512_ICL\n"
     ]
    }
   ],
   "source": [
    "np.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, xv, yt, yv = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signatures/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     return list(chain.from_iterable((_safe_indexing(a, train),\n\u001b[0m\u001b[1;32m   2200\u001b[0m                                      _safe_indexing(a, test)) for a in arrays))\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signatures/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n\u001b[0;32m-> 2200\u001b[0;31m                                      _safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signatures/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signatures/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[0;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xt, xv, yt, yv = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5670331790123457"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ELM Optimization\n",
    "\n",
    "ELM itself can run on my laptop, and evaluate all results on the laptop.\n",
    "\n",
    "ELM *Optimization* is what runs in the cloud - it gathers statistics of many many ELM trials with different random combinations of parameters. Tighter parameter ranges and good combinations are dsicovered through this random search process, iteration by iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': loguniform(1e-2, 1e+2),\n",
    "    'ufunc': ['tanh', 'sigm', 'relu', 'lin'],\n",
    "    'pairwise_metric': [None, 'euclidean', 'cityblock', 'cosine'],\n",
    "    'density': loguniform(0.001, 1),\n",
    "    'n_neurons': loguniform(10, 10000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv = RandomizedSearchCV(\n",
    "    skelm.ELMClassifier(), params, n_iter=4, scoring='accuracy', cv=3, refit=False,\n",
    "    verbose=3, n_jobs=None, return_train_score=True\n",
    ")\n",
    "rcv.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rcv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actually run the ELM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcv = RandomizedSearchCV(skelm.ELMClassifier(), params, n_iter=100, scoring='accuracy', cv=3, refit=False)\n",
    "rcv.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 5):  #100000\n",
    "    rcv = RandomizedSearchCV(skelm.ELMClassifier(), params, n_iter=100, scoring='accuracy', cv=3, refit=False)\n",
    "    res = rcv.fit(x, y)\n",
    "    pd.DataFrame(res.cv_results_).to_pickle(\"res_v2/res_v2_{}.pkl\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat((pd.read_pickle(\"res_v2/res_v2_{}.pkl\".format(i)) for i in range(9999) if os.path.isfile(\"res_v2/res_v2_{}.pkl\".format(i))))\n",
    "Z = Z.reset_index(drop=True)\n",
    "Z = Z.drop([\"params\", \"param_pairwise_metric\", \"param_ufunc\"] , axis=1)\n",
    "\n",
    "Z['param_n_neurons'] = Z['param_n_neurons'].apply(lambda a : a // 50 * 50)\n",
    "Z['param_density'] = Z['param_density'].apply(lambda a : (a + 0.05)//0.1 * 0.1)\n",
    "Z['param_alpha'] = Z['param_alpha'].apply(lambda a : np.log10(a)//0.5 * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "P_10k = pd.pivot_table(Z, index='param_n_neurons', columns='param_alpha', values=\"mean_test_score\")\n",
    "# sn.heatmap(P, vmin=0.61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname0 = \"res_v2/res_v2_{}_n100000.pkl\"\n",
    "Z = pd.concat((pd.read_pickle(fname0.format(i)) for i in range(9999) if os.path.isfile(fname0.format(i))))\n",
    "Z = Z.reset_index(drop=True)\n",
    "Z = Z.drop([\"params\", \"param_pairwise_metric\", \"param_ufunc\"] , axis=1)\n",
    "\n",
    "Z['param_n_neurons'] = Z['param_n_neurons'].apply(lambda a : a // 50 * 50)\n",
    "Z['param_density'] = Z['param_density'].apply(lambda a : (a + 0.05)//0.1 * 0.1)\n",
    "Z['param_alpha'] = Z['param_alpha'].apply(lambda a : np.log10(a)//0.5 * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "P = pd.pivot_table(Z, index='param_n_neurons', columns='param_alpha', values=\"mean_test_score\")\n",
    "sn.heatmap(P, vmin=0.64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance vs number of training samples, best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = next(GroupShuffleSplit().split(x, y, groups))\n",
    "xt, xs, yt, ys = x[train_idx], x[test_idx], y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "model = skelm.ELMClassifier(n_neurons=2000, alpha=0.3, batch_size=5000)\n",
    "\n",
    "for j in np.logspace(3, np.log10(xt.shape[0]), num=30):\n",
    "    jj = int(j)\n",
    "    print(jj, end=' ... ')\n",
    "    t = time()\n",
    "    score = model.fit(x[:jj], y[:jj]).score(xs, ys)\n",
    "    data.append({'N': j, 'score': score})\n",
    "    t = time() - t\n",
    "    print(\"{:.3f} : {:.1f}s\".format(score, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.DataFrame(data)\n",
    "Z.plot(x='N', y='score', logx=True, figsize=(15, 7), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "model = skelm.ELMClassifier(n_neurons=2000, alpha=0.3, batch_size=5000)\n",
    "\n",
    "for j in np.logspace(3, np.log10(xt.shape[0]), num=30):\n",
    "    jj = int(j)\n",
    "    print(jj, end=' ... ')\n",
    "    t = time()\n",
    "    score = model.fit(x[:jj], y[:jj]).score(xs, ys)\n",
    "    data.append({'N': j, 'score': score})\n",
    "    t = time() - t\n",
    "    print(\"{:.3f} : {:.1f}s\".format(score, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.DataFrame(data)\n",
    "Z.plot(x='N', y='score', logx=True, figsize=(15, 7), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune best parameters for limited-sample models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [4110, 5700, 10890]\n",
    "Ns = [int(n * (30/27) * (3/2)) for n in Ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': loguniform(1e+1, 1e+4),\n",
    "    'n_neurons': loguniform(2000, 10000),\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res1 = []\n",
    "res2 = []\n",
    "res3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 500):\n",
    "    for n1, res in zip(Ns, (res1, res2, res3)):\n",
    "        rcv = RandomizedSearchCV(skelm.ELMClassifier(batch_size=10000), params, n_iter=20, scoring='accuracy', cv=3, refit=False)\n",
    "        res.append(pd.DataFrame(rcv.fit(x[:n1], y[:n1]).cv_results_))\n",
    "        print(\"{}:{}\".format(i, n1//1000), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res123_current.pkl\", \"wb\") as fr:\n",
    "    pickle.dump({\"res1\": res1, \"res2\": res2, \"res3\":res3}, fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, sharey=True, figsize=(18, 8))#, gridspec_kw={'hspace': 0, 'wspace': 0.3})\n",
    "fig.suptitle('Horizontally stacked subplots')\n",
    "\n",
    "k = 0\n",
    "for res, ax in zip([res1, res2, res3], axes):\n",
    "    k += 1\n",
    "    Z = pd.concat(res)\n",
    "    Z['neurons'] = Z['param_n_neurons'].apply(lambda a : 2 ** (np.log2(a) // 0.15 * 0.15)).astype(int)\n",
    "    Z['alpha'] = Z['param_alpha'].apply(lambda a : np.log10(a)//0.2 * 0.2).apply(lambda a: np.round(a, 1))\n",
    "    P = pd.pivot_table(Z, index='neurons', columns='alpha', values=\"mean_test_score\")\n",
    "    sn.heatmap(P, ax=ax, square=True, cbar=False, vmin=0.6)\n",
    "    ax.set_title([4110, 5700, 10890][k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, sharey=True, figsize=(18, 8))#, gridspec_kw={'hspace': 0, 'wspace': 0.3})\n",
    "fig.suptitle('Horizontally stacked subplots')\n",
    "\n",
    "k = 0\n",
    "for res, ax in zip([res1, res2, res3], axes):\n",
    "    k += 1\n",
    "    Z = pd.concat(res)\n",
    "    Z['neurons'] = Z['param_n_neurons'].apply(lambda a : 2 ** (np.log2(a) // 0.15 * 0.15)).astype(int)\n",
    "    Z['alpha'] = Z['param_alpha'].apply(lambda a : np.log10(a)//0.2 * 0.2).apply(lambda a: np.round(a, 1))\n",
    "    P = pd.pivot_table(Z[(Z.alpha > 0.5) & (Z.alpha < 4.1) & (Z.neurons > 500)], \n",
    "                       index='neurons', columns='alpha', values=\"mean_test_score\")\n",
    "    sn.heatmap(P, ax=ax, square=True, cbar=False, vmin=0.6)\n",
    "    ax.set_title([4110, 5700, 10890][k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, sharey=True, figsize=(12, 8))#, gridspec_kw={'hspace': 0, 'wspace': 0.3})\n",
    "fig.suptitle('Horizontally stacked subplots')\n",
    "\n",
    "k = 0\n",
    "for res, ax in zip([res1, res2, res3], axes):\n",
    "    k += 1\n",
    "    Z = pd.concat(res)\n",
    "    Z['neurons'] = Z['param_n_neurons'].apply(lambda a : a // 100 * 100).astype(np.int)\n",
    "    Z['alpha'] = Z['param_alpha'].apply(lambda a : np.log10(a)//0.5 * 0.5)\n",
    "    P = pd.pivot_table(Z, index='neurons', columns='alpha', values=\"mean_test_score\")\n",
    "    sn.heatmap(P, ax=ax, square=False, cbar=k==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(\"/home/akusok/HDD2TB/MCYTD_10p_n100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat((\n",
    "    pd.get_dummies(X.uid, prefix='user'),\n",
    "    X.drop(['wsize', 'overlap', 'xmin', 'ymin', 'xmax', 'ymax', 'uid'], axis=1)\n",
    "), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.loc[:, '0':'1023'] = Z.loc[:, '0':'1023'] - Z.loc[:, '0':'1023'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip low standard deviation to avoid excessively large numbers\n",
    "Z.loc[:, '0':'1023'] = Z.loc[:, '0':'1023'] / Z.loc[:, '0':'1023'].std().clip(lower=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the value range\n",
    "Z.loc[:, '0':'1023'] = Z.loc[:, '0':'1023'].clip(lower=-5.0, upper=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Z.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Z.sig_true)\n",
    "x = np.array(Z.drop(['sig_true', 'fid'], axis=1))\n",
    "groups = Z.fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skelm.ELMClassifier(alpha=10, n_neurons=1000, ufunc='sigm', density=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvp = cross_val_predict(model, x, y, groups=groups, cv=GroupKFold(n_splits=10), n_jobs=3, pre_dispatch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/akusok/HDD2TB/MCYTD_10p_n100-predict.npy\", cvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
