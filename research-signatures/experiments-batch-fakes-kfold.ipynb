{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify images using data of only 1 user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all data from 1 user, split in groups by image id.\n",
    "\n",
    "Learn to classify True/Fake patches, then combine them into True/Fake images by majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import skelm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, cross_val_score, GridSearchCV, GroupShuffleSplit, RandomizedSearchCV\n",
    "import scipy\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from time import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Users/akusok/wrkdir/research-signatures-data/MCYTDB\"\n",
    "overlap = '50p'\n",
    "samples = 10000000 // 30\n",
    "\n",
    "data_file = \"/Users/akusok/wrkdir/research-signatures-data/MCYTD_overlap{}.pkl\".format(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and run default ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.loc[:, 'sig_true'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, '0':'1023'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = data.loc[:, 'uid'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X - X.mean()\n",
    "X = X / X.std().clip(min=0.5)\n",
    "X = X.clip(min=-5, max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = data.loc[:, 'fid'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skelm.ELMClassifier(alpha=0.8, n_neurons=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2157, 1.0, 0.71900826446281]\n",
      "[330, 0.0, 0.42699724517906334]\n",
      "[900, 1.0, 0.6391184573002755]\n",
      "[1440, 0.0, 0.4462809917355372]\n",
      "[960, 1.0, 0.7823691460055097]\n",
      "[2047, 1.0, 0.8264462809917356]\n",
      "[1020, 1.0, 0.8154269972451791]\n",
      "[1980, 0.0, 0.15151515151515152]\n",
      "[1950, 1.0, 0.7603305785123967]\n",
      "[990, 1.0, 0.6418732782369146]\n",
      "[450, 1.0, 0.628099173553719]\n",
      "[2040, 0.0, 0.05234159779614325]\n",
      "[1530, 1.0, 0.8953168044077136]\n",
      "[1350, 1.0, 0.6831955922865014]\n",
      "[1535, 1.0, 0.22038567493112948]\n",
      "[1589, 1.0, 0.5344352617079889]\n",
      "[2010, 0.0, 0.24242424242424243]\n",
      "[510, 1.0, 0.4380165289256198]\n",
      "[1470, 0.0, 0.27823691460055094]\n",
      "[480, 1.0, 0.928374655647383]\n",
      "[870, 0.0, 0.2231404958677686]\n",
      "[1023, 1.0, 0.7768595041322314]\n",
      "[511, 1.0, 0.44077134986225897]\n",
      "[1320, 1.0, 0.2727272727272727]\n",
      "[930, 1.0, 0.1349862258953168]\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=25)\n",
    "res = []\n",
    "for i, (ti, vi) in enumerate(gkf.split(X, Y, G)):\n",
    "    model.fit(X[ti], Y[ti])\n",
    "    yh = model.predict(X[vi])\n",
    "    yv = Y[vi]\n",
    "    gv = G[vi]\n",
    "    fv = F[vi]\n",
    "    for j in set(fv):\n",
    "        res.append([j, yv[fv == j].mean(), yh[fv == j].mean()])\n",
    "        \n",
    "    with open(\"res_gkf_{}.pkl\".format(i), \"wb\") as fout:\n",
    "        pickle.dump(res, fout)\n",
    "    \n",
    "    print(res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res_gkf_{}.pkl\".format(25-1), \"rb\") as fin:\n",
    "    res = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = res[:, 1].astype(np.int)\n",
    "y_pred = res[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y, y_pred, pos_label=1)\n",
    "fnr = 1 - tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48760330578512395"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eer_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32355555555555554"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32533333333333336"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5, 23, 35, 50, 72, 87, 100, 115}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def process_user(u0, model):\n",
    "    \n",
    "    for root,_,files in os.walk(\"{}/{}/overlap{}\".format(data_folder, u0, overlap)):\n",
    "        data_files = [os.path.join(root, f) for f in files if f.endswith(\".parquet.gz\")]\n",
    "    \n",
    "    data = []\n",
    "    for i, df0 in enumerate(data_files):\n",
    "        X = pd.read_parquet(df0).loc[:, '0':]\n",
    "        X = X.sample(min(len(X), samples))\n",
    "        X['fake'] = int(\"/cf-\" in df0)\n",
    "        X['group'] = i\n",
    "        data.append(X)\n",
    "    data = pd.concat(data).reset_index(drop=True)    \n",
    "    \n",
    "    group = np.array(data['group'])\n",
    "    y = np.array(data['fake'])\n",
    "    X = np.array(data.loc[:, :'1023'])\n",
    "    X = X - X.mean()\n",
    "    X = X / X.std().clip(min=0.5)\n",
    "    X = X.clip(min=-5, max=5)\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=10)\n",
    "    res = []\n",
    "    for ti, vi in gkf.split(X, y, group):\n",
    "        model.fit(X[ti], y[ti])\n",
    "        yh = model.predict(X[vi])\n",
    "        yv = y[vi]\n",
    "        gv = group[vi]\n",
    "        for j in set(gv):\n",
    "            res.append([j, yv[gv == j].mean(), yh[gv == j].mean()])\n",
    "\n",
    "    res = np.array(res)\n",
    "    res = res[np.argsort(res[:,2])]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "V = {}\n",
    "model = skelm.ELMClassifier(alpha=0.3, n_neurons=1900)\n",
    "\n",
    "for usr in users:\n",
    "    res = process_user(usr, model)\n",
    "    V[usr] = res\n",
    "    \n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.plot(res[:, 2])\n",
    "    i0 = np.where(res[:, 1] == 0)[0]\n",
    "    plt.plot(i0, [0]*len(i0), \"*g\")\n",
    "\n",
    "    i1 = np.where(res[:, 1] == 1)[0]\n",
    "    plt.plot(i1, [1]*len(i1), \"*r\")\n",
    "    plt.title(\"User: \"+usr)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
