{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.utils import check_X_y, check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - CUDA Runtime 11.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_61,code=sm_61\n",
      "  - CuDNN 8.0.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.__config__.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e+4\n",
    "L = 5000\n",
    "d = 1024\n",
    "bsize = 5000\n",
    "N = 50000\n",
    "use_original_features = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_original_features:\n",
    "    W = np.random.randn(d, L+d+1)\n",
    "    W[:, 1:d+1] = np.eye(d)\n",
    "else:\n",
    "    W = np.random.randn(d, L+1)    \n",
    "    \n",
    "W[:,0] = 0  # bias\n",
    "\n",
    "W = W.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test with single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(bsize, d) + 1\n",
    "x = x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.46 s, sys: 158 ms, total: 4.62 s\n",
      "Wall time: 845 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = x @ W\n",
    "h[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 ms, sys: 3.51 ms, total: 38.8 ms\n",
      "Wall time: 9.41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_gpu = torch.from_numpy(x).float().cuda()\n",
    "w_gpu = torch.from_numpy(W).float().cuda()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 4.69 ms, total: 109 ms\n",
      "Wall time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h_gpu = x_gpu.matmul(w_gpu)\n",
    "h_gpu[:, 0] = 1\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(h, h_gpu.cpu().numpy(), atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test with solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(bsize, d) + 1\n",
    "x = x.astype(np.float32)\n",
    "\n",
    "y = np.random.randint(0, 3, size=(bsize, 1)) * 10\n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 s, sys: 148 ms, total: 4.49 s\n",
      "Wall time: 761 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = x @ W\n",
    "h[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 320 ms, total: 10.9 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hh = h.T @ h + np.eye(h.shape[1]) * alpha\n",
    "hy = h.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.88 s, sys: 131 ms, total: 9.01 s\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "B = sp.linalg.cho_solve(sp.linalg.cho_factor(hh), hy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.1 ms, sys: 487 Âµs, total: 58.5 ms\n",
      "Wall time: 9.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_gpu = torch.from_numpy(x).float().cuda()\n",
    "y_gpu = torch.from_numpy(y).float().cuda()\n",
    "w_gpu = torch.from_numpy(W).float().cuda()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 141 ms, sys: 4.03 ms, total: 145 ms\n",
      "Wall time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h_gpu = x_gpu.matmul(w_gpu)\n",
    "h_gpu[:, 0] = 1\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 223 ms, sys: 4.12 ms, total: 227 ms\n",
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hh_gpu = torch.eye(W.shape[1], device=\"cuda\") * alpha\n",
    "hh_gpu += torch.mm(h_gpu.t(), h_gpu)\n",
    "\n",
    "hy_gpu = torch.mm(h_gpu.t(), y_gpu)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 347 ms, sys: 20 ms, total: 367 ms\n",
      "Wall time: 68.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "u_gpu = torch.cholesky(hh_gpu)\n",
    "b_gpu = torch.cholesky_solve(hy_gpu, u_gpu)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(B, b_gpu.cpu().numpy(), atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### total runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 555 ms, total: 23.2 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "h = x @ W\n",
    "h[:, 0] = 1\n",
    "hh = h.T @ h + np.eye(h.shape[1]) * alpha\n",
    "hy = h.T @ y\n",
    "B = sp.linalg.cho_solve(sp.linalg.cho_factor(hh), hy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 470 ms, sys: 32.3 ms, total: 502 ms\n",
      "Wall time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_gpu = torch.from_numpy(x).float().cuda()\n",
    "y_gpu = torch.from_numpy(y).float().cuda()\n",
    "w_gpu = torch.from_numpy(W).float().cuda()\n",
    "\n",
    "h_gpu = x_gpu.matmul(w_gpu)\n",
    "hh_gpu = torch.eye(W.shape[1], device=\"cuda\") * alpha\n",
    "hh_gpu += torch.mm(h_gpu.t(), h_gpu)\n",
    "\n",
    "hy_gpu = torch.mm(h_gpu.t(), y_gpu)\n",
    "h_gpu[:, 0] = 1\n",
    "\n",
    "u_gpu = torch.cholesky(hh_gpu)\n",
    "b_gpu = torch.cholesky_solve(hy_gpu, u_gpu)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 174 ms, sys: 11.6 ms, total: 185 ms\n",
      "Wall time: 30.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "b2_gpu, _ = torch.solve(hy_gpu, hh_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.77 s, sys: 140 ms, total: 2.91 s\n",
      "Wall time: 490 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "u,w,vt = torch.svd(hh_gpu)\n",
    "b_svd_gpu = vt.t().mm(torch.diag(w**-1)).mm(u.t()).mm(hy_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7394e-10, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 7.3006e-07, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 7.5296e-07,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7257e-02, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.8681e-02,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         3.1827e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(w**-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,w,vt = np.linalg.svd(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73941277e-10, 7.30046159e-07, 7.52959338e-07, ...,\n",
       "       1.01914932e-01, 1.02018615e-01, 1.02233093e-01])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w**-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2051],\n",
       "        [ 0.0204],\n",
       "        [-0.2191],\n",
       "        ...,\n",
       "        [ 0.2357],\n",
       "        [-0.1553],\n",
       "        [ 0.0789]], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_svd_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2881],\n",
       "        [ 0.2666],\n",
       "        [-0.6483],\n",
       "        ...,\n",
       "        [ 0.0094],\n",
       "        [ 0.0300],\n",
       "        [-0.0045]], device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2924],\n",
       "        [ 0.2421],\n",
       "        [-0.6439],\n",
       "        ...,\n",
       "        [ 0.0103],\n",
       "        [ 0.0285],\n",
       "        [-0.0028]], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29529522],\n",
       "       [ 0.20233413],\n",
       "       [-0.66505539],\n",
       "       ...,\n",
       "       [ 0.00827873],\n",
       "       [ 0.03210935],\n",
       "       [-0.0048997 ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(B, b_svd_gpu.cpu().numpy(), atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2973300394470932"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(B - b_svd_gpu.cpu().numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016163080938343684"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(B - b_gpu.cpu().numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01516888651084861"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(B - b2_gpu.cpu().numpy()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test async HPELM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_Inception21k\t\t\t\t\tMCYTD_overlap25p_n200.pkl\n",
      "GPDSS10000\t\t\t\t\tMCYTD_overlap50p_n200.pkl\n",
      "Inception21k_feature_extractor_save_parquet.py\tMCYTD_overlap90p_n200.pkl\n",
      "jpg2png.py\t\t\t\t\tresults.err\n",
      "lost+found\t\t\t\t\tresults_gpds.err\n",
      "MCYTD_10p_n100.pkl\t\t\t\tresults_gpds.out\n",
      "MCYTD_10p_n100-predict.npy\t\t\tresults.out\n",
      "MCYTD_10p_n150.pkl\t\t\t\ttemp1.pkl\n",
      "MCYTD_90p_n100.pkl\t\t\t\ttest.py\n",
      "MCYTDB\t\t\t\t\t\tuntitled.txt\n",
      "MCYTD_overlap10p_n200.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls /home/akusok/HDD2TB/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpelm import HPELM\n",
    "from hpelm import nnets\n",
    "from hpelm.modules import make_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x = np.random.randn(100_000, 100).astype(np.float32)\n",
    "    y = np.random.rand(100_000, 3).astype(np.float32)\n",
    "    make_hdf5(x, \"/home/akusok/HDD2TB/test_x_{}.h5\".format(i), dtype=np.float32)\n",
    "    make_hdf5(y, \"/home/akusok/HDD2TB/test_y_{}.h5\".format(i), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA GPU acceleration with Scikit-CUDA\n"
     ]
    }
   ],
   "source": [
    "model = HPELM(inputs=100, outputs=3, accelerator=\"GPU\", precision=np.float32, batch=2000)\n",
    "model.add_neurons(10000, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 29/50, eta 0:00:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 3.24171 s\n",
       "File: /home/akusok/miniconda3/envs/torch/lib/python3.8/site-packages/hpelm/nnets/slfn_skcuda.py\n",
       "Function: _project at line 170\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   170                                               def _project(self, X, dev=False):\n",
       "   171                                                   \"\"\"Projects X to H, an auxiliary function that implements a particular projection.\n",
       "   172                                           \n",
       "   173                                                   For actual projection, use `ELM.project()` instead.\n",
       "   174                                           \n",
       "   175                                                   Args:\n",
       "   176                                                       X (matrix): an input data matrix, size (N * `inputs`)\n",
       "   177                                                       dev (bool, optional): whether leave result in the GPU memory\n",
       "   178                                           \n",
       "   179                                                   Returns:\n",
       "   180                                                       H (matrix): an SLFN hidden layer representation, size (N * `L`) where 'L' is number of neurons\n",
       "   181                                                   \"\"\"\n",
       "   182        50         59.0      1.2      0.0          assert self.neurons is not None, \"ELM has no neurons\"\n",
       "   183        50       4488.0     89.8      0.1          X = np.array(X, order=\"C\", dtype=self.precision)\n",
       "   184        50     140412.0   2808.2      4.3          devX = gpuarray.to_gpu(X)\n",
       "   185        50      28495.0    569.9      0.9          devH = gpuarray.empty((X.shape[0], self.L), dtype=self.precision)\n",
       "   186        50         71.0      1.4      0.0          i = 0\n",
       "   187       100        124.0      1.2      0.0          for nn, ftype, devW, devB in self.neurons:\n",
       "   188        50    3067870.0  61357.4     94.6              devH[:, i:i+nn] = self.func[ftype](devX, devW, devB)\n",
       "   189        50        111.0      2.2      0.0              i += nn\n",
       "   190                                           \n",
       "   191        50         46.0      0.9      0.0          H = devH if dev else devH.get()\n",
       "   192        50         39.0      0.8      0.0          return H\n",
       "\n",
       "Total time: 3.7601 s\n",
       "File: /home/akusok/miniconda3/envs/torch/lib/python3.8/site-packages/hpelm/nnets/slfn_skcuda.py\n",
       "Function: add_batch at line 212\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   212                                               def add_batch(self, X, T, wc=None):\n",
       "   213                                                   \"\"\"Add a batch of training data to an iterative solution, weighted if neeed.\n",
       "   214                                           \n",
       "   215                                                   The batch is processed as a whole, the training data is splitted in `ELM.add_data()` method.\n",
       "   216                                                   With parameters HH_out, HT_out, the output will be put into these matrices instead of model.\n",
       "   217                                           \n",
       "   218                                                   Args:\n",
       "   219                                                       X (matrix): input data matrix size (N * `inputs`)\n",
       "   220                                                       T (matrix): output data matrix size (N * `outputs`)\n",
       "   221                                                       wc (vector): vector of weights for data samples, one weight per sample, size (N * 1)\n",
       "   222                                                       HH_out, HT_out (matrix, optional): output matrices to add batch result into, always given together\n",
       "   223                                                   \"\"\"\n",
       "   224        50    3345923.0  66918.5     89.0          devH = self._project(X, dev=True)\n",
       "   225        50        757.0     15.1      0.0          T = np.array(T, order=\"C\", dtype=self.precision)\n",
       "   226        50      11203.0    224.1      0.3          devT = gpuarray.to_gpu(T)\n",
       "   227        50        100.0      2.0      0.0          if wc is not None:  # apply weights if given\n",
       "   228                                                       w = np.array(wc**0.5, dtype=self.precision)[:, None]  # re-shape to column matrix\n",
       "   229                                                       devWC = gpuarray.to_gpu(w)\n",
       "   230                                                       misc.mult_matvec(devH, devWC, axis=0, out=devH)\n",
       "   231                                                       misc.mult_matvec(devT, devWC, axis=0, out=devT)\n",
       "   232                                           \n",
       "   233        50         81.0      1.6      0.0          if self.HH is None:  # initialize space for self.HH, self.HT\n",
       "   234         1     126685.0 126685.0      3.4              self.HT = misc.zeros((self.L, self.outputs), dtype=self.precision)\n",
       "   235         1     123596.0 123596.0      3.3              self.HH = linalg.eye(self.L, dtype=self.precision)\n",
       "   236         1     121758.0 121758.0      3.2              self.HH *= self.norm\n",
       "   237                                           \n",
       "   238        50       3732.0     74.6      0.1          linalg.add_dot(devH, devT, self.HT, transa='T')\n",
       "   239        50        131.0      2.6      0.0          if self.precision is np.float64:\n",
       "   240                                                       linalg.add_dot(devH, devH, self.HH, transa='T')\n",
       "   241                                                   else:\n",
       "   242        50      26139.0    522.8      0.7              cublas.cublasSsyrk(self.handle, 'L', 'N', self.L, X.shape[0], 1, devH.ptr, self.L, 1, self.HH.ptr, self.L)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "%lprun -f model.nnet.add_batch -f model.nnet._project model.add_data(\"/home/akusok/HDD2TB/test_x_{}.h5\".format(i), \"/home/akusok/HDD2TB/test_y_{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.610306 s\n",
       "File: /home/akusok/miniconda3/envs/torch/lib/python3.8/site-packages/hpelm/nnets/slfn_skcuda.py\n",
       "Function: _project at line 170\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   170                                               def _project(self, X, dev=False):\n",
       "   171                                                   \"\"\"Projects X to H, an auxiliary function that implements a particular projection.\n",
       "   172                                           \n",
       "   173                                                   For actual projection, use `ELM.project()` instead.\n",
       "   174                                           \n",
       "   175                                                   Args:\n",
       "   176                                                       X (matrix): an input data matrix, size (N * `inputs`)\n",
       "   177                                                       dev (bool, optional): whether leave result in the GPU memory\n",
       "   178                                           \n",
       "   179                                                   Returns:\n",
       "   180                                                       H (matrix): an SLFN hidden layer representation, size (N * `L`) where 'L' is number of neurons\n",
       "   181                                                   \"\"\"\n",
       "   182        50         68.0      1.4      0.0          assert self.neurons is not None, \"ELM has no neurons\"\n",
       "   183        50       6124.0    122.5      1.0          X = np.array(X, order=\"C\", dtype=self.precision)\n",
       "   184        50      42667.0    853.3      7.0          devX = gpuarray.to_gpu(X)\n",
       "   185        50      28144.0    562.9      4.6          devH = gpuarray.empty((X.shape[0], self.L), dtype=self.precision)\n",
       "   186        50         68.0      1.4      0.0          i = 0\n",
       "   187       100        139.0      1.4      0.0          for nn, ftype, devW, devB in self.neurons:\n",
       "   188        50     532898.0  10658.0     87.3              devH[:, i:i+nn] = self.func[ftype](devX, devW, devB)\n",
       "   189        50        116.0      2.3      0.0              i += nn\n",
       "   190                                           \n",
       "   191        50         41.0      0.8      0.0          H = devH if dev else devH.get()\n",
       "   192        50         41.0      0.8      0.0          return H\n",
       "\n",
       "Total time: 0.74394 s\n",
       "File: /home/akusok/miniconda3/envs/torch/lib/python3.8/site-packages/hpelm/nnets/slfn_skcuda.py\n",
       "Function: add_batch at line 212\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   212                                               def add_batch(self, X, T, wc=None):\n",
       "   213                                                   \"\"\"Add a batch of training data to an iterative solution, weighted if neeed.\n",
       "   214                                           \n",
       "   215                                                   The batch is processed as a whole, the training data is splitted in `ELM.add_data()` method.\n",
       "   216                                                   With parameters HH_out, HT_out, the output will be put into these matrices instead of model.\n",
       "   217                                           \n",
       "   218                                                   Args:\n",
       "   219                                                       X (matrix): input data matrix size (N * `inputs`)\n",
       "   220                                                       T (matrix): output data matrix size (N * `outputs`)\n",
       "   221                                                       wc (vector): vector of weights for data samples, one weight per sample, size (N * 1)\n",
       "   222                                                       HH_out, HT_out (matrix, optional): output matrices to add batch result into, always given together\n",
       "   223                                                   \"\"\"\n",
       "   224        50     726315.0  14526.3     97.6          devH = self._project(X, dev=True)\n",
       "   225        50        875.0     17.5      0.1          T = np.array(T, order=\"C\", dtype=self.precision)\n",
       "   226        50      10243.0    204.9      1.4          devT = gpuarray.to_gpu(T)\n",
       "   227        50        103.0      2.1      0.0          if wc is not None:  # apply weights if given\n",
       "   228                                                       w = np.array(wc**0.5, dtype=self.precision)[:, None]  # re-shape to column matrix\n",
       "   229                                                       devWC = gpuarray.to_gpu(w)\n",
       "   230                                                       misc.mult_matvec(devH, devWC, axis=0, out=devH)\n",
       "   231                                                       misc.mult_matvec(devT, devWC, axis=0, out=devT)\n",
       "   232                                           \n",
       "   233        50         85.0      1.7      0.0          if self.HH is None:  # initialize space for self.HH, self.HT\n",
       "   234                                                       self.HT = misc.zeros((self.L, self.outputs), dtype=self.precision)\n",
       "   235                                                       self.HH = linalg.eye(self.L, dtype=self.precision)\n",
       "   236                                                       self.HH *= self.norm\n",
       "   237                                           \n",
       "   238        50       3873.0     77.5      0.5          linalg.add_dot(devH, devT, self.HT, transa='T')\n",
       "   239        50        135.0      2.7      0.0          if self.precision is np.float64:\n",
       "   240                                                       linalg.add_dot(devH, devH, self.HH, transa='T')\n",
       "   241                                                   else:\n",
       "   242        50       2311.0     46.2      0.3              cublas.cublasSsyrk(self.handle, 'L', 'N', self.L, X.shape[0], 1, devH.ptr, self.L, 1, self.HH.ptr, self.L)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "%lprun -f model.nnet.add_batch -f model.nnet._project model.add_data_async(\"/home/akusok/HDD2TB/test_x_{}.h5\".format(i), \"/home/akusok/HDD2TB/test_y_{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 2.36 s, total: 35.5 s\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10):\n",
    "    model.add_data_async(\"/home/akusok/HDD2TB/test_x_{}.h5\".format(i), \"/home/akusok/HDD2TB/test_y_{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 s, sys: 2.44 s, total: 34.9 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10):\n",
    "    model.add_data(\"/home/akusok/HDD2TB/test_x_{}.h5\".format(i), \"/home/akusok/HDD2TB/test_y_{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchCholeskySolver(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, alpha=1e-7):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _init_XY(self, X, y):\n",
    "        \"\"\"Initialize covariance matrices, including a separate bias term.\n",
    "        \"\"\"\n",
    "        d_in = X.shape[1]\n",
    "        self._XtX = np.eye(d_in + 1) * self.alpha\n",
    "        self._XtX[0, 0] = 0\n",
    "        if len(y.shape) == 1:\n",
    "            self._XtY = np.zeros((d_in + 1,)) \n",
    "        else:\n",
    "            self._XtY = np.zeros((d_in + 1, y.shape[1]))\n",
    "\n",
    "    @property\n",
    "    def XtY_(self):\n",
    "        return self._XtY\n",
    "\n",
    "    @property\n",
    "    def XtX_(self):\n",
    "        return self._XtX\n",
    "\n",
    "    @XtY_.setter\n",
    "    def XtY_(self, value):\n",
    "        self._XtY = value\n",
    "\n",
    "    @XtX_.setter\n",
    "    def XtX_(self, value):\n",
    "        self._XtX = value\n",
    "\n",
    "    def _solve(self):\n",
    "        \"\"\"Second stage of solution (X'X)B = X'Y using Cholesky decomposition.\n",
    "\n",
    "        Sets `is_fitted_` to True.\n",
    "        \"\"\"\n",
    "        #todo: auto increase 'alpha' parameter if the solution fails\n",
    "        B = sp.linalg.solve(self._XtX, self._XtY, assume_a='pos', overwrite_a=False, overwrite_b=False)\n",
    "        self.coef_ = B[1:]\n",
    "        self.intercept_ = B[0]\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Erase solution and data matrices.\n",
    "        \"\"\"\n",
    "        [delattr(self, attr) for attr in ('_XtX', '_XtY', 'coef_', 'intercept_', 'is_fitted_') if hasattr(self, attr)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Solves an L2-regularized linear system like Ridge regression, overwrites any previous solutions.\n",
    "        \"\"\"\n",
    "        self._reset()  # remove old solution\n",
    "        self.partial_fit(X, y, compute_output_weights=True)\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, compute_output_weights=True):\n",
    "        \"\"\"Update model with a new batch of data.\n",
    "        \n",
    "        Output weight computation can be temporary turned off for faster processing. This will mark model as\n",
    "        not fit. Enable `compute_output_weights` in the final call to `partial_fit`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape=[n_samples, n_features]\n",
    "            Training input samples\n",
    "\n",
    "        y : array-like, shape=[n_samples, n_targets]\n",
    "            Training targets\n",
    "\n",
    "        compute_output_weights : boolean, optional, default True\n",
    "            Whether to compute new output weights (coef_, intercept_). Disable this in intermediate `partial_fit`\n",
    "            steps to run computations faster, then enable in the last call to compute the new solution.\n",
    "\n",
    "            .. Note::\n",
    "                Solution can be updated without extra data by setting `X=None` and `y=None`.\n",
    "        \"\"\"\n",
    "        if self.alpha < 0:\n",
    "            raise ValueError(\"Regularization parameter alpha must be non-negative.\")\n",
    "\n",
    "        # solution only\n",
    "        if X is None and y is None and compute_output_weights:\n",
    "            self._solve()\n",
    "            return self\n",
    "\n",
    "        # validate parameters\n",
    "        X, y = check_X_y(X, y, accept_sparse=True, multi_output=True, y_numeric=True, ensure_2d=True)\n",
    "        if len(y.shape) > 1 and y.shape[1] == 1:\n",
    "            msg = \"A column-vector y was passed when a 1d array was expected.\\\n",
    "                   Please change the shape of y to (n_samples, ), for example using ravel().\"\n",
    "            warnings.warn(msg, DataConversionWarning)\n",
    "        \n",
    "        # init temporary data storage\n",
    "        if not hasattr(self, '_XtX'):\n",
    "            self._init_XY(X, y)\n",
    "        else:\n",
    "            if X.shape[1] + 1 != self._XtX.shape[0]:\n",
    "                n_new, n_old = X.shape[1], self._XtX.shape[0] - 1\n",
    "                raise ValueError(\"Number of features %d does not match previous data %d.\" % (n_new, n_old))\n",
    "                \n",
    "        # compute temporary data\n",
    "        X_sum = safe_sparse_dot(X.T, np.ones((X.shape[0],)))\n",
    "        y_sum = safe_sparse_dot(y.T, np.ones((y.shape[0],)))\n",
    "        self._XtX[0, 0] += X.shape[0]\n",
    "        self._XtX[1:, 0] += X_sum\n",
    "        self._XtX[0, 1:] += X_sum\n",
    "        self._XtX[1:, 1:] += X.T @ X\n",
    "\n",
    "        self._XtY[0] += y_sum\n",
    "        self._XtY[1:] += X.T @ y\n",
    "        \n",
    "        # solve\n",
    "        if not compute_output_weights:\n",
    "            # mark as not fitted\n",
    "            [delattr(self, attr) for attr in ('coef_', 'intercept_', 'is_fitted_') if hasattr(self, attr)]\n",
    "        else:\n",
    "            self._solve()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        return safe_sparse_dot(X, self.coef_, dense_output=True) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
